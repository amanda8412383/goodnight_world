{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import logging\n",
    "\n",
    "\n",
    "import codecs\n",
    "import unidecode\n",
    "import re\n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "#from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from autocorrect import spell\n",
    "    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix    \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## labels\n",
    "0 - work\n",
    "\n",
    "1 - industry \n",
    "\n",
    "2 - politic\n",
    "\n",
    "3 - life and family\n",
    "\n",
    "4 - charity\n",
    "\n",
    "5 - flaunt wealth\n",
    "\n",
    "6 - sport event or hobbies\n",
    "\n",
    "7 - public activity\n",
    "\n",
    "8 - personal development of the CEO\n",
    "\n",
    "9 - current events and social issues\n",
    "\n",
    "10 - others\n",
    "\n",
    "<br/><br/>\n",
    "## reference\n",
    "### - basic concept : \n",
    "https://www.linkedin.com/pulse/text-classification-using-bag-words-approach-nltk-scikit-rajendran/\n",
    "\n",
    "this post should split data earlier\n",
    "\n",
    "### - model selection: \n",
    "https://realpython.com/python-keras-text-classification/\n",
    "\n",
    "### - the post is mainly followed: \n",
    "https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568\n",
    "\n",
    "### - its imbalance version: \n",
    "https://towardsdatascience.com/multi-class-text-classification-with-scikit-learn-12f1e60e0a9f\n",
    "\n",
    "### - imbalanced data processing using tweet as example\n",
    "https://towardsdatascience.com/yet-another-twitter-sentiment-analysis-part-1-tackling-class-imbalance-4d7a7f717d44\n",
    "\n",
    "### -imbalanced data with kera\n",
    "https://towardsdatascience.com/machine-learning-multiclass-classification-with-imbalanced-data-set-29f6a177c1\n",
    "\n",
    "<br/><br/>\n",
    "## import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_id</th>\n",
       "      <th>label</th>\n",
       "      <th>sub_label</th>\n",
       "      <th>fulltext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'935610534489219072</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our #1 best seller, Japanese Cherry Blossom, sells 30.2 million products each year!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'935613720650309632</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I  got my start in 1963, when I  used a $5,000 loan from my aunt to open The Limited.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'967109017502851072</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Can?? blame a guy for trying #respect @StephenCurry30 https://t.co/gAlWIDVwQJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'1011457609180667909</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love @TeamLou23 He really earned the sixth man of the year. All @LAClippers fans show him some appreciation!!!  Thanks Lou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'928115711943348224</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Want to know what commitment and determination look like? Great @SInow piece on @blakegriffin32 https://t.co/GV7NNHhffT #ItTakesEverything</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              status_id label sub_label  \\\n",
       "0  '935610534489219072   0     NaN        \n",
       "1  '935613720650309632   0     NaN        \n",
       "2  '967109017502851072   6     NaN        \n",
       "3  '1011457609180667909  6     NaN        \n",
       "4  '928115711943348224   6     NaN        \n",
       "\n",
       "                                                                                                                                     fulltext  \n",
       "0  Our #1 best seller, Japanese Cherry Blossom, sells 30.2 million products each year!                                                         \n",
       "1  I  got my start in 1963, when I  used a $5,000 loan from my aunt to open The Limited.                                                       \n",
       "2  Can?? blame a guy for trying #respect @StephenCurry30 https://t.co/gAlWIDVwQJ                                                               \n",
       "3  Love @TeamLou23 He really earned the sixth man of the year. All @LAClippers fans show him some appreciation!!!  Thanks Lou                  \n",
       "4  Want to know what commitment and determination look like? Great @SInow piece on @blakegriffin32 https://t.co/GV7NNHhffT #ItTakesEverything  "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prestore it as txt to make inread data prettier\n",
    "#change sub label to sub_label\n",
    "dataset = pd.read_csv(r'tweet label2.txt',  engine = \"python\", index_col=False, skiprows = 0, \n",
    "        encoding =\"ISO-8859-1\", na_values = '-', delimiter =',', skipinitialspace=True, quotechar='\"')\n",
    "    \n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean wired data cause by csv \n",
    "#delete if label is not number or not null\n",
    "dataset['problem_l'] = ~dataset.label.astype(str).apply(lambda x: x.isnumeric())\n",
    "dataset['problem_s'] = ~dataset.label.isnull() \n",
    "dataset['problem_sub_l'] = ~dataset.sub_label.astype(str).apply(lambda x: x.isnumeric())\n",
    "dataset['problem_sub_s'] = ~dataset.sub_label.isnull() \n",
    "dataset = dataset.drop(dataset[((dataset.problem_l) & (dataset.problem_s)) | ((dataset.problem_sub_l) & (dataset.problem_sub_s)) ].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7     605\n",
       "0     589\n",
       "1     583\n",
       "9     236\n",
       "10    125\n",
       "6     106\n",
       "2     100\n",
       "4     62 \n",
       "3     57 \n",
       "8     26 \n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "dataset.label.value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "dataset.sub_label.value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row : 186769\n",
      "words : 3192313\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 186769 entries, 0 to 187276\n",
      "Data columns (total 8 columns):\n",
      "status_id        186706 non-null object\n",
      "label            2489 non-null object\n",
      "sub_label        966 non-null object\n",
      "fulltext         186688 non-null object\n",
      "problem_l        186769 non-null bool\n",
      "problem_s        186769 non-null bool\n",
      "problem_sub_l    186769 non-null bool\n",
      "problem_sub_s    186769 non-null bool\n",
      "dtypes: bool(4), object(4)\n",
      "memory usage: 7.8+ MB\n"
     ]
    }
   ],
   "source": [
    "print('row :', dataset.shape[0])\n",
    "print('words :', dataset['fulltext'].astype(str).apply(lambda x: len(x.split(' '))).sum())\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_id</th>\n",
       "      <th>fulltext</th>\n",
       "      <th>label</th>\n",
       "      <th>sub_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'935610534489219072</td>\n",
       "      <td>Our #1 best seller, Japanese Cherry Blossom, sells 30.2 million products each year!</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'935613720650309632</td>\n",
       "      <td>I  got my start in 1963, when I  used a $5,000 loan from my aunt to open The Limited.</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'967109017502851072</td>\n",
       "      <td>Can?? blame a guy for trying #respect @StephenCurry30 https://t.co/gAlWIDVwQJ</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'1011457609180667909</td>\n",
       "      <td>Love @TeamLou23 He really earned the sixth man of the year. All @LAClippers fans show him some appreciation!!!  Thanks Lou</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'928115711943348224</td>\n",
       "      <td>Want to know what commitment and determination look like? Great @SInow piece on @blakegriffin32 https://t.co/GV7NNHhffT #ItTakesEverything</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              status_id  \\\n",
       "0  '935610534489219072    \n",
       "1  '935613720650309632    \n",
       "2  '967109017502851072    \n",
       "3  '1011457609180667909   \n",
       "4  '928115711943348224    \n",
       "\n",
       "                                                                                                                                     fulltext  \\\n",
       "0  Our #1 best seller, Japanese Cherry Blossom, sells 30.2 million products each year!                                                          \n",
       "1  I  got my start in 1963, when I  used a $5,000 loan from my aunt to open The Limited.                                                        \n",
       "2  Can?? blame a guy for trying #respect @StephenCurry30 https://t.co/gAlWIDVwQJ                                                                \n",
       "3  Love @TeamLou23 He really earned the sixth man of the year. All @LAClippers fans show him some appreciation!!!  Thanks Lou                   \n",
       "4  Want to know what commitment and determination look like? Great @SInow piece on @blakegriffin32 https://t.co/GV7NNHhffT #ItTakesEverything   \n",
       "\n",
       "  label sub_label  \n",
       "0  0     NaN       \n",
       "1  0     NaN       \n",
       "2  6     NaN       \n",
       "3  6     NaN       \n",
       "4  6     NaN       "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = dataset[['status_id', 'fulltext', 'label', 'sub_label']]\n",
    "text = text[text['status_id'].notnull()]\n",
    "text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_type = text.astype({\"status_id\":'str', \"fulltext\":'str', \"label\":'float', \"sub_label\":'float'})\n",
    "# text_type.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \n",
    "                   \"can't've\": \"cannot have\", \"'cause\": \"because\", \"could've\": \"could have\", \n",
    "                   \"couldn't\": \"could not\", \"couldn't've\": \"could not have\",\"didn't\": \"did not\", \n",
    "                   \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \n",
    "                   \"hadn't've\": \"had not have\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \n",
    "                   \"he'd\": \"he would\", \"he'd've\": \"he would have\", \"he'll\": \"he will\", \n",
    "                   \"he'll've\": \"he will have\", \"he's\": \"he is\", \"how'd\": \"how did\", \n",
    "                   \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\", \n",
    "                   \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \n",
    "                   \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \n",
    "                   \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\", \n",
    "                   \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \n",
    "                   \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \n",
    "                   \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \n",
    "                   \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \n",
    "                   \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \n",
    "                   \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \n",
    "                   \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \n",
    "                   \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\n",
    "                   \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \n",
    "                   \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \n",
    "                   \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \n",
    "                   \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \n",
    "                   \"this's\": \"this is\",\n",
    "                   \"that'd\": \"that would\", \"that'd've\": \"that would have\",\"that's\": \"that is\", \n",
    "                   \"there'd\": \"there would\", \"there'd've\": \"there would have\",\"there's\": \"there is\", \n",
    "                       \"here's\": \"here is\",\n",
    "                   \"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \n",
    "                   \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \n",
    "                   \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \n",
    "                   \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \n",
    "                   \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \n",
    "                   \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\", \n",
    "                   \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \n",
    "                   \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \n",
    "                   \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \n",
    "                   \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \n",
    "                   \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \n",
    "                   \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \n",
    "                   \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "                   \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                   \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \n",
    "                   \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: invalid escape sequence '\\s'\n",
      "  \n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: invalid escape sequence '\\c'\n",
      "  \n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: invalid escape sequence '\\ '\n",
      "  \n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: invalid escape sequence '\\d'\n",
      "  \n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: invalid escape sequence '\\e'\n",
      "  \n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: invalid escape sequence '\\('\n",
      "  \n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: invalid escape sequence '\\o'\n",
      "  \n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: invalid escape sequence '\\_'\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def spacy_cleaner(text):\n",
    "    #lower case\n",
    "    text = text.lower()\n",
    "    #unicode_escape for extra \"\\\" before unicode character, then unidecode\n",
    "    try:\n",
    "        decoded = unidecode.unidecode(codecs.decode(text, 'unicode_escape'))\n",
    "    except:\n",
    "        decoded = unidecode.unidecode(text)\n",
    "    #there are apostrophe and singlequote people use for contraction. any apostrophe) is changed to single quote\n",
    "    apostrophe_handled = re.sub(\"’\", \"'\", decoded)\n",
    "    #Contraction check\n",
    "    expanded = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in apostrophe_handled.split(\" \")])\n",
    "    parsed = nlp(expanded)\n",
    "    final_tokens = []\n",
    "    for t in parsed:\n",
    "        #Filtering punctuation, white space, numbers, URL using Spacy methods while keeping the text content of hashtag intact\n",
    "        #Removed @mention\n",
    "        if t.is_punct or t.is_space or t.like_num or t.like_url or str(t).startswith('@'):            \n",
    "            pass\n",
    "        else:\n",
    "            #Pronouns are kept as they are since Spacy lemmatizer transforms every pronoun to \"-PRON-\"\n",
    "            if t.lemma_ == '-PRON-':\n",
    "                final_tokens.append(str(t))\n",
    "            else:\n",
    "                #Lemmatize: lemmatized each token using Spacy method '.lemma_'.\n",
    "                #Special character removal\n",
    "                sc_removed = re.sub(\"[^a-zA-Z]\", '', str(t.lemma_))\n",
    "                #Single syllable token removal\n",
    "                if len(sc_removed) > 1:\n",
    "                    final_tokens.append(sc_removed)\n",
    "    \"\"\"joined = ' '.join(PorterStemmer().stem(spell(word)) for word in final_tokens if word not in STOPWORDS) \"\"\" \n",
    "    # delete stopwors from text,  finding the base word, auto correct\n",
    "    joined = ' '.join(final_tokens)\n",
    "    #it is a simple spell correction, if the same character is repeated more than two times, it shortens the repetition to two\n",
    "    spell_corrected = re.sub(r'(.)\\1+', r'\\1\\1', joined)\n",
    "    return spell_corrected\n",
    "\n",
    "\n",
    "text['cleantext'] = text['fulltext'].astype(str).apply(spacy_cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2734623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    our good seller japanese cherry blossom sell product each year                            \n",
       "1    get my start in when use loan from my aunt to open the limited                            \n",
       "2    can blame guy for try respect                                                             \n",
       "3    love he really earn the sixth man of the year all fan show him some appreciation thank lou\n",
       "4    want to know what commitment and determination look like great piece on ittakeseverything \n",
       "Name: cleantext, dtype: object"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "#\n",
    "print(text['cleantext'].apply(lambda x: len(x.split(' '))).sum())\n",
    "text['cleantext'].head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              status_id  \\\n",
      "0  '935610534489219072    \n",
      "1  '935613720650309632    \n",
      "2  '967109017502851072    \n",
      "3  '1011457609180667909   \n",
      "4  '928115711943348224    \n",
      "\n",
      "                                                                                                                                     fulltext  \\\n",
      "0  Our #1 best seller, Japanese Cherry Blossom, sells 30.2 million products each year!                                                          \n",
      "1  I  got my start in 1963, when I  used a $5,000 loan from my aunt to open The Limited.                                                        \n",
      "2  Can?? blame a guy for trying #respect @StephenCurry30 https://t.co/gAlWIDVwQJ                                                                \n",
      "3  Love @TeamLou23 He really earned the sixth man of the year. All @LAClippers fans show him some appreciation!!!  Thanks Lou                   \n",
      "4  Want to know what commitment and determination look like? Great @SInow piece on @blakegriffin32 https://t.co/GV7NNHhffT #ItTakesEverything   \n",
      "\n",
      "  label sub_label  \\\n",
      "0  0     NaN        \n",
      "1  0     NaN        \n",
      "2  6     NaN        \n",
      "3  6     NaN        \n",
      "4  6     NaN        \n",
      "\n",
      "                                                                                    cleantext  \n",
      "0  our good seller japanese cherry blossom sell product each year                              \n",
      "1  get my start in when use loan from my aunt to open the limited                              \n",
      "2  can blame guy for try respect                                                               \n",
      "3  love he really earn the sixth man of the year all fan show him some appreciation thank lou  \n",
      "4  want to know what commitment and determination look like great piece on ittakeseverything   \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2489 entries, 0 to 2498\n",
      "Data columns (total 5 columns):\n",
      "status_id    2489 non-null object\n",
      "fulltext     2487 non-null object\n",
      "label        2489 non-null object\n",
      "sub_label    966 non-null object\n",
      "cleantext    2489 non-null object\n",
      "dtypes: object(5)\n",
      "memory usage: 116.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df = text[text['label'].notnull()]\n",
    "print(df.head())\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 status_id  \\\n",
      "901   '1121480618867666950   \n",
      "1356  '704360252368506880    \n",
      "1367  '279689055862669312    \n",
      "1775  '695432140700282886    \n",
      "2387  '1078292356636397569   \n",
      "\n",
      "                                                                                                                                                                 fulltext  \\\n",
      "901   Blast from the past!?\\n?\\nOver 30 years ago to be exact!\\n?\\nI guess I had not learned how to use lower case letters at that point ?????????https://t.co/JPXo6TuN4M   \n",
      "1356  Student-centered learning yields better education outcomes https://t.co/e2fHOBk7vo                                                                                    \n",
      "1367  From our great customer event at Dell World this week at Darrell K Royal ??Texas Memorial Stadium http://t.co/jqb6vsob                                                \n",
      "1775  See you at https://t.co/OXdGxkRlVE! :) https://t.co/YsADlWDkF5                                                                                                        \n",
      "2387  ??                                                                                                                                                                    \n",
      "\n",
      "     label sub_label  \\\n",
      "901   NaN   NaN        \n",
      "1356  NaN   NaN        \n",
      "1367  NaN   NaN        \n",
      "1775  NaN   NaN        \n",
      "2387  NaN   NaN        \n",
      "\n",
      "                                                                                                        cleantext  \n",
      "901   blast from the past over year ago to be exact guess have not learn how to use low case letter at that point  \n",
      "1356  student center learning yield well education outcome                                                         \n",
      "1367  from our great customer event at dell world this week at darrell royal texas memorial stadium                \n",
      "1775  see you at                                                                                                   \n",
      "2387                                                                                                               \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 184217 entries, 901 to 187276\n",
      "Data columns (total 5 columns):\n",
      "status_id    184217 non-null object\n",
      "fulltext     184201 non-null object\n",
      "label        0 non-null object\n",
      "sub_label    0 non-null object\n",
      "cleantext    184217 non-null object\n",
      "dtypes: object(5)\n",
      "memory usage: 8.4+ MB\n"
     ]
    }
   ],
   "source": [
    "## unlabeled data that need to be predicted\n",
    "df_test = text[text['label'].isnull()]\n",
    "print(df_test.head())\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try ordinary approach on imbalanced data \n",
    "<br/><br/>\n",
    "### result explaination\n",
    "#### - Accuracy\n",
    "Classification accuracy is our starting point. It is the number of correct predictions made divided by the total number of predictions made, multiplied by 100 to turn it into a percentage.\n",
    "\n",
    "#### -Precision\n",
    "Precision is the number of True Positives divided by the number of True Positives and False Positives. Put another way, it is the number of positive predictions divided by the total number of positive class values predicted. It is also called the Positive Predictive Value (PPV).\n",
    "Precision can be thought of as a measure of a classifiers exactness. A low precision can also indicate a large number of False Positives.\n",
    "\n",
    "#### - Recall\n",
    "Recall is the number of True Positives divided by the number of True Positives and the number of False Negatives. Put another way it is the number of positive predictions divided by the number of positive class values in the test data. It is also called Sensitivity or the True Positive Rate.\n",
    "Recall can be thought of as a measure of a classifiers completeness. A low recall indicates many False Negatives.\n",
    "\n",
    "#### - F1 score\n",
    "F1 = 2 * (precision * recall) / (precision + recall)\n",
    "The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0. The relative contribution of precision and recall to the F1 score are equal.\n",
    "In the multi-class and multi-label case, this is the average of the F1 score of each class with weighting depending on the average parameter.\n",
    "\n",
    "#### Sourxe\n",
    "https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "### sklearn.feature_extraction.text.TfidfVectorizer \n",
    "#### parameter\n",
    "- sublinear_df is set to True to use a logarithmic form for frequency.\n",
    "- min_df is the minimum numbers of documents a word must be present in to be kept.\n",
    "- norm is set to l2, to ensure all our feature vectors have a euclidian norm of 1.\n",
    "\n",
    "norm：一般譯成範數\n",
    "\n",
    "(norm 有規範的意思，也就是加上規範使其正常化)，建議把 Norm 想成長度就好 (事實上norm是長度的抽象推廣)\n",
    "\n",
    "https://ch-hsieh.blogspot.com/2010/04/norm.html\n",
    "\n",
    "- ngram_range is set to (1, 2) to indicate that we want to consider both unigrams and bigrams.\n",
    "\n",
    "n-gram is basically set of occurring words within given window \n",
    "\n",
    "https://stackoverflow.com/questions/43463792/what-is-the-difference-between-bigram-and-unigram-text-features-extract\n",
    "- stop_words can be set to \"english\" to remove all common pronouns (\"a\", \"the\", ...) to reduce the number of noisy features.\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "\n",
    "### parameter for precision_score\n",
    "- 'macro': Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting variable for n fold and average method\n",
    "split = 5\n",
    "avg_method = 'macro'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def result printintg function\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def lr_cv(splits, X, Y, pipeline, average_method):\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=splits, shuffle=True, random_state=777)\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    for train, test in kfold.split(X, Y):\n",
    "        lr_fit = pipeline.fit(X[train], Y[train])\n",
    "        prediction = lr_fit.predict(X[test])\n",
    "        scores = lr_fit.score(X[test],Y[test])\n",
    "\n",
    "        print('accuracy %s' % accuracy_score(prediction, Y[test]))\n",
    "        print(classification_report(Y[test], prediction))\n",
    "\n",
    "        accuracy.append(scores * 100)\n",
    "        precision.append(precision_score(Y[test], prediction, average=average_method)*100)\n",
    "        recall.append(recall_score(Y[test], prediction, average=average_method)*100)\n",
    "        f1.append(f1_score(Y[test], prediction, average=average_method)*100)\n",
    "        print('-'*50)\n",
    "\n",
    "    print(\"accuracy: %.2f%% (+/- %.2f%%)\" % (np.mean(accuracy), np.std(accuracy)))\n",
    "    print(\"precision: %.2f%% (+/- %.2f%%)\" % (np.mean(precision), np.std(precision)))\n",
    "    print(\"recall: %.2f%% (+/- %.2f%%)\" % (np.mean(recall), np.std(recall)))\n",
    "    print(\"f1 score: %.2f%% (+/- %.2f%%)\" % (np.mean(f1), np.std(f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvec = TfidfVectorizer(stop_words=None, max_features=100000, ngram_range=(1, 3))\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.4760956175298805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.67      0.61       118\n",
      "           1       0.42      0.51      0.46       117\n",
      "          10       0.67      0.16      0.26        25\n",
      "           2       0.00      0.00      0.00        20\n",
      "           3       0.00      0.00      0.00        12\n",
      "           4       1.00      0.15      0.27        13\n",
      "           6       0.00      0.00      0.00        22\n",
      "           7       0.45      0.77      0.57       121\n",
      "           8       0.00      0.00      0.00         6\n",
      "           9       1.00      0.02      0.04        48\n",
      "\n",
      "    accuracy                           0.48       502\n",
      "   macro avg       0.41      0.23      0.22       502\n",
      "weighted avg       0.49      0.48      0.41       502\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.47695390781563124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.62      0.59       118\n",
      "           1       0.42      0.53      0.47       117\n",
      "          10       1.00      0.04      0.08        25\n",
      "           2       0.00      0.00      0.00        20\n",
      "           3       0.00      0.00      0.00        12\n",
      "           4       1.00      0.23      0.38        13\n",
      "           6       0.00      0.00      0.00        21\n",
      "           7       0.46      0.82      0.59       121\n",
      "           8       0.00      0.00      0.00         5\n",
      "           9       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.48       499\n",
      "   macro avg       0.34      0.22      0.21       499\n",
      "weighted avg       0.42      0.48      0.40       499\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.45875251509054327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.59      0.57       118\n",
      "           1       0.38      0.46      0.42       117\n",
      "          10       0.17      0.04      0.06        25\n",
      "           2       0.00      0.00      0.00        20\n",
      "           3       0.00      0.00      0.00        11\n",
      "           4       0.50      0.08      0.14        12\n",
      "           6       0.00      0.00      0.00        21\n",
      "           7       0.46      0.84      0.60       121\n",
      "           8       0.00      0.00      0.00         5\n",
      "           9       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.46       497\n",
      "   macro avg       0.21      0.20      0.18       497\n",
      "weighted avg       0.35      0.46      0.39       497\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.4596774193548387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.65      0.60       118\n",
      "           1       0.44      0.47      0.45       116\n",
      "          10       0.33      0.08      0.13        25\n",
      "           2       0.00      0.00      0.00        20\n",
      "           3       0.00      0.00      0.00        11\n",
      "           4       1.00      0.17      0.29        12\n",
      "           6       0.00      0.00      0.00        21\n",
      "           7       0.41      0.76      0.54       121\n",
      "           8       0.00      0.00      0.00         5\n",
      "           9       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.46       496\n",
      "   macro avg       0.27      0.21      0.20       496\n",
      "weighted avg       0.38      0.46      0.39       496\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.46464646464646464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.66      0.57       117\n",
      "           1       0.47      0.52      0.49       116\n",
      "          10       1.00      0.08      0.15        25\n",
      "           2       0.00      0.00      0.00        20\n",
      "           3       0.00      0.00      0.00        11\n",
      "           4       1.00      0.08      0.15        12\n",
      "           6       0.00      0.00      0.00        21\n",
      "           7       0.43      0.74      0.54       121\n",
      "           8       0.00      0.00      0.00         5\n",
      "           9       1.00      0.02      0.04        47\n",
      "\n",
      "    accuracy                           0.46       495\n",
      "   macro avg       0.44      0.21      0.19       495\n",
      "weighted avg       0.50      0.46      0.40       495\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "accuracy: 46.72% (+/- 0.79%)\n",
      "precision: 33.43% (+/- 8.58%)\n",
      "recall: 21.55% (+/- 0.96%)\n",
      "f1 score: 20.07% (+/- 1.38%)\n"
     ]
    }
   ],
   "source": [
    "# use original data\n",
    "original_pipeline = Pipeline([\n",
    "    ('vectorizer', tvec),\n",
    "    ('classifier', lr)\n",
    "])\n",
    "\n",
    "lr_cv(split, df['cleantext'].values.astype(str), df['label'].values.astype(str), original_pipeline, avg_method)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split test & train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.cleantext\n",
    "y = df.label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 1)\n",
    "#random_state is equal to set seed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset need prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = df.cleantext\n",
    "y_train2 =  df.label\n",
    "X_test2 = df_test.cleantext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomOverSampler¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  train  Multinomial Naive Bayes \n",
    "as a simple baseline\n",
    "<br/><br/>\n",
    "### reference \n",
    "#### -why is pipeline essential &rarr; \n",
    "to keep train and test data fit correctly during cross validation \n",
    "\n",
    "https://towardsdatascience.com/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976 \n",
    "\n",
    "#### -what is CountVectorizer &rarr; \n",
    "An encoded vector is returned with a length of the entire vocabulary and an integer count for the number of times each word appeared in the document.\n",
    "#### -what is TfidfTransformer &rarr; \n",
    "“Term Frequency – Inverse Document” Frequency which are the components of the resulting scores assigned to each word.Term Frequency summarizes how often a given word appears within a document. Inverse Document Frequency downscales words that appear a lot across documents.\n",
    "\n",
    "https://machinelearningmastery.com/prepare-text-data-machine-learning-scikit-learn/\n",
    "#### -what is  Multinomial Naive Bayes classifier &rarr; \n",
    "a specific instance of a Naive Bayes classifier which uses a multinomial distribution for each of the features\n",
    "\n",
    "https://stats.stackexchange.com/questions/33185/difference-between-naive-bayes-multinomial-naive-bayes\n",
    "\n",
    "Multinomial Distribution \n",
    "\n",
    "https://www.tutorialspoint.com/statistics/multinomial_distribution.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.4641434262948207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.66      0.60       118\n",
      "           1       0.47      0.44      0.46       117\n",
      "          10       0.00      0.00      0.00        25\n",
      "           2       0.00      0.00      0.00        20\n",
      "           3       0.00      0.00      0.00        12\n",
      "           4       1.00      0.15      0.27        13\n",
      "           6       0.00      0.00      0.00        22\n",
      "           7       0.40      0.83      0.54       121\n",
      "           8       0.00      0.00      0.00         6\n",
      "           9       0.00      0.00      0.00        48\n",
      "\n",
      "    accuracy                           0.46       502\n",
      "   macro avg       0.24      0.21      0.19       502\n",
      "weighted avg       0.36      0.46      0.39       502\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "accuracy 0.46893787575150303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.62      0.59       118\n",
      "           1       0.49      0.48      0.48       117\n",
      "          10       0.00      0.00      0.00        25\n",
      "           2       0.00      0.00      0.00        20\n",
      "           3       0.00      0.00      0.00        12\n",
      "           4       1.00      0.23      0.38        13\n",
      "           6       0.00      0.00      0.00        21\n",
      "           7       0.40      0.84      0.55       121\n",
      "           8       0.00      0.00      0.00         5\n",
      "           9       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.47       499\n",
      "   macro avg       0.25      0.22      0.20       499\n",
      "weighted avg       0.37      0.47      0.40       499\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "accuracy 0.4426559356136821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.60      0.57       118\n",
      "           1       0.43      0.37      0.40       117\n",
      "          10       0.00      0.00      0.00        25\n",
      "           2       0.00      0.00      0.00        20\n",
      "           3       0.00      0.00      0.00        11\n",
      "           4       0.50      0.08      0.14        12\n",
      "           6       0.00      0.00      0.00        21\n",
      "           7       0.40      0.87      0.55       121\n",
      "           8       0.00      0.00      0.00         5\n",
      "           9       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.44       497\n",
      "   macro avg       0.19      0.19      0.17       497\n",
      "weighted avg       0.34      0.44      0.36       497\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "accuracy 0.48185483870967744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.65      0.61       118\n",
      "           1       0.52      0.45      0.48       116\n",
      "          10       0.00      0.00      0.00        25\n",
      "           2       0.00      0.00      0.00        20\n",
      "           3       0.00      0.00      0.00        11\n",
      "           4       1.00      0.17      0.29        12\n",
      "           6       0.00      0.00      0.00        21\n",
      "           7       0.41      0.89      0.57       121\n",
      "           8       0.00      0.00      0.00         5\n",
      "           9       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.48       496\n",
      "   macro avg       0.25      0.22      0.19       496\n",
      "weighted avg       0.38      0.48      0.40       496\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "accuracy 0.4686868686868687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.70      0.61       117\n",
      "           1       0.49      0.42      0.46       116\n",
      "          10       0.00      0.00      0.00        25\n",
      "           2       0.00      0.00      0.00        20\n",
      "           3       0.00      0.00      0.00        11\n",
      "           4       1.00      0.08      0.15        12\n",
      "           6       0.00      0.00      0.00        21\n",
      "           7       0.41      0.83      0.55       121\n",
      "           8       0.00      0.00      0.00         5\n",
      "           9       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.47       495\n",
      "   macro avg       0.24      0.20      0.18       495\n",
      "weighted avg       0.37      0.47      0.39       495\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "accuracy: 46.53% (+/- 1.28%)\n",
      "precision: 23.45% (+/- 2.39%)\n",
      "recall: 20.76% (+/- 0.92%)\n",
      "f1 score: 18.48% (+/- 1.23%)\n"
     ]
    }
   ],
   "source": [
    "#vectorizer => transformer => classifier\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "lr_cv(split, df['cleantext'].values.astype(str), df['label'].values.astype(str), nb, avg_method)\n",
    "\n",
    "#nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.4538152610441767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.63      0.61       185\n",
      "           1       0.50      0.39      0.44       188\n",
      "          10       0.00      0.00      0.00        32\n",
      "           2       0.00      0.00      0.00        27\n",
      "           3       0.00      0.00      0.00        20\n",
      "           4       0.00      0.00      0.00        17\n",
      "           6       0.00      0.00      0.00        32\n",
      "           7       0.37      0.85      0.51       174\n",
      "           8       0.00      0.00      0.00         8\n",
      "           9       0.00      0.00      0.00        64\n",
      "\n",
      "    accuracy                           0.45       747\n",
      "   macro avg       0.15      0.19      0.16       747\n",
      "weighted avg       0.36      0.45      0.38       747\n",
      "\n",
      "Wall time: 53 ms\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# y_pred = nb.predict(X_test)\n",
    "\n",
    "# print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try to predict unlabeled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "nb.fit(X_train2, y_train2)\n",
    "df_test['y_pred'] = nb.predict(X_test2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_id</th>\n",
       "      <th>fulltext</th>\n",
       "      <th>label</th>\n",
       "      <th>sub_label</th>\n",
       "      <th>cleantext</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>'1121480618867666950</td>\n",
       "      <td>Blast from the past!?\\n?\\nOver 30 years ago to be exact!\\n?\\nI guess I had not learned how to use lower case letters at that point ?????????https://t.co/JPXo6TuN4M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>blast from the past over year ago to be exact guess have not learn how to use low case letter at that point</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>'704360252368506880</td>\n",
       "      <td>Student-centered learning yields better education outcomes https://t.co/e2fHOBk7vo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>student center learning yield well education outcome</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>'279689055862669312</td>\n",
       "      <td>From our great customer event at Dell World this week at Darrell K Royal ??Texas Memorial Stadium http://t.co/jqb6vsob</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>from our great customer event at dell world this week at darrell royal texas memorial stadium</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>'695432140700282886</td>\n",
       "      <td>See you at https://t.co/OXdGxkRlVE! :) https://t.co/YsADlWDkF5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>see you at</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>'1078292356636397569</td>\n",
       "      <td>??</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 status_id  \\\n",
       "901   '1121480618867666950   \n",
       "1356  '704360252368506880    \n",
       "1367  '279689055862669312    \n",
       "1775  '695432140700282886    \n",
       "2387  '1078292356636397569   \n",
       "\n",
       "                                                                                                                                                                 fulltext  \\\n",
       "901   Blast from the past!?\\n?\\nOver 30 years ago to be exact!\\n?\\nI guess I had not learned how to use lower case letters at that point ?????????https://t.co/JPXo6TuN4M   \n",
       "1356  Student-centered learning yields better education outcomes https://t.co/e2fHOBk7vo                                                                                    \n",
       "1367  From our great customer event at Dell World this week at Darrell K Royal ??Texas Memorial Stadium http://t.co/jqb6vsob                                                \n",
       "1775  See you at https://t.co/OXdGxkRlVE! :) https://t.co/YsADlWDkF5                                                                                                        \n",
       "2387  ??                                                                                                                                                                    \n",
       "\n",
       "     label sub_label  \\\n",
       "901   NaN   NaN        \n",
       "1356  NaN   NaN        \n",
       "1367  NaN   NaN        \n",
       "1775  NaN   NaN        \n",
       "2387  NaN   NaN        \n",
       "\n",
       "                                                                                                        cleantext  \\\n",
       "901   blast from the past over year ago to be exact guess have not learn how to use low case letter at that point   \n",
       "1356  student center learning yield well education outcome                                                          \n",
       "1367  from our great customer event at dell world this week at darrell royal texas memorial stadium                 \n",
       "1775  see you at                                                                                                    \n",
       "2387                                                                                                                \n",
       "\n",
       "     y_pred  \n",
       "901   0      \n",
       "1356  1      \n",
       "1367  7      \n",
       "1775  7      \n",
       "2387  7      "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Support Vector Machine \n",
    "widely regarded as one of the best text classification algorithms\n",
    "\n",
    "## note :\n",
    "SGDClassifier is not a classifier but a linear classifier optimized by the SGD. It implements by regularising linear models with Stochastic Gradient Descent.\n",
    "\n",
    "clf = SGDClassifier( class_weight='balanced', alpha=i, penalty='l2', loss='hinge', random_state=42) it is an implementation of Linear SVM. loss=\"hinge\": (soft-margin) linear Support Vector Machine.\n",
    "\n",
    "clf = SGDClassifier( class_weight='balanced', alpha=i, penalty='l2', loss='log', random_state=42) . It is an implementation of Logisitic regression.\n",
    "## reference:\n",
    "### -How to make SGD Classifier perform as well as Logistic Regression using parfit\n",
    "https://towardsdatascience.com/how-to-make-sgd-classifier-perform-as-well-as-logistic-regression-using-parfit-cc10bca2d3c4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5159362549800797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.70      0.61       118\n",
      "           1       0.46      0.39      0.42       117\n",
      "          10       0.39      0.28      0.33        25\n",
      "           2       0.45      0.25      0.32        20\n",
      "           3       0.33      0.08      0.13        12\n",
      "           4       0.80      0.62      0.70        13\n",
      "           6       0.58      0.32      0.41        22\n",
      "           7       0.53      0.73      0.61       121\n",
      "           8       0.00      0.00      0.00         6\n",
      "           9       0.48      0.29      0.36        48\n",
      "\n",
      "    accuracy                           0.52       502\n",
      "   macro avg       0.46      0.37      0.39       502\n",
      "weighted avg       0.50      0.52      0.49       502\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "accuracy 0.5250501002004008\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.64      0.59       118\n",
      "           1       0.50      0.50      0.50       117\n",
      "          10       0.33      0.12      0.18        25\n",
      "           2       0.78      0.35      0.48        20\n",
      "           3       0.00      0.00      0.00        12\n",
      "           4       0.55      0.46      0.50        13\n",
      "           6       0.44      0.19      0.27        21\n",
      "           7       0.53      0.74      0.62       121\n",
      "           8       0.67      0.40      0.50         5\n",
      "           9       0.52      0.36      0.43        47\n",
      "\n",
      "    accuracy                           0.53       499\n",
      "   macro avg       0.49      0.38      0.41       499\n",
      "weighted avg       0.51      0.53      0.50       499\n",
      "\n",
      "--------------------------------------------------\n",
      "accuracy 0.5171026156941649\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.60      0.57       118\n",
      "           1       0.43      0.41      0.42       117\n",
      "          10       0.09      0.04      0.06        25\n",
      "           2       0.43      0.15      0.22        20\n",
      "           3       0.25      0.09      0.13        11\n",
      "           4       0.88      0.58      0.70        12\n",
      "           6       0.77      0.48      0.59        21\n",
      "           7       0.56      0.85      0.68       121\n",
      "           8       1.00      0.20      0.33         5\n",
      "           9       0.44      0.26      0.32        47\n",
      "\n",
      "    accuracy                           0.52       497\n",
      "   macro avg       0.54      0.37      0.40       497\n",
      "weighted avg       0.50      0.52      0.49       497\n",
      "\n",
      "--------------------------------------------------\n",
      "accuracy 0.5241935483870968\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.68      0.61       118\n",
      "           1       0.46      0.36      0.41       116\n",
      "          10       0.36      0.20      0.26        25\n",
      "           2       0.64      0.45      0.53        20\n",
      "           3       0.33      0.09      0.14        11\n",
      "           4       0.83      0.42      0.56        12\n",
      "           6       0.58      0.33      0.42        21\n",
      "           7       0.52      0.80      0.63       121\n",
      "           8       0.00      0.00      0.00         5\n",
      "           9       0.64      0.30      0.41        47\n",
      "\n",
      "    accuracy                           0.52       496\n",
      "   macro avg       0.49      0.36      0.40       496\n",
      "weighted avg       0.52      0.52      0.50       496\n",
      "\n",
      "--------------------------------------------------\n",
      "accuracy 0.48282828282828283\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.65      0.56       117\n",
      "           1       0.46      0.38      0.42       116\n",
      "          10       0.31      0.16      0.21        25\n",
      "           2       0.38      0.15      0.21        20\n",
      "           3       0.00      0.00      0.00        11\n",
      "           4       0.88      0.58      0.70        12\n",
      "           6       0.67      0.19      0.30        21\n",
      "           7       0.49      0.74      0.59       121\n",
      "           8       1.00      0.20      0.33         5\n",
      "           9       0.48      0.21      0.29        47\n",
      "\n",
      "    accuracy                           0.48       495\n",
      "   macro avg       0.51      0.33      0.36       495\n",
      "weighted avg       0.48      0.48      0.45       495\n",
      "\n",
      "--------------------------------------------------\n",
      "accuracy: 51.30% (+/- 1.55%)\n",
      "precision: 49.77% (+/- 2.75%)\n",
      "recall: 35.96% (+/- 1.69%)\n",
      "f1 score: 39.10% (+/- 1.58%)\n"
     ]
    }
   ],
   "source": [
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "               ])\n",
    "lr_cv(split, df['cleantext'].values.astype(str), df['label'].values.astype(str), sgd, avg_method)\n",
    "\n",
    "# sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # \n",
    "# y_pred = sgd.predict(X_test)\n",
    "\n",
    "# print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.4243027888446215\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.52      0.48       118\n",
      "           1       0.35      0.44      0.39       117\n",
      "          10       0.21      0.24      0.22        25\n",
      "           2       0.42      0.25      0.31        20\n",
      "           3       0.40      0.17      0.24        12\n",
      "           4       0.67      0.46      0.55        13\n",
      "           6       0.60      0.27      0.37        22\n",
      "           7       0.50      0.51      0.51       121\n",
      "           8       1.00      0.17      0.29         6\n",
      "           9       0.44      0.25      0.32        48\n",
      "\n",
      "    accuracy                           0.42       502\n",
      "   macro avg       0.50      0.33      0.37       502\n",
      "weighted avg       0.44      0.42      0.42       502\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.45490981963927857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.53      0.51       118\n",
      "           1       0.41      0.44      0.43       117\n",
      "          10       0.25      0.20      0.22        25\n",
      "           2       0.50      0.30      0.37        20\n",
      "           3       0.00      0.00      0.00        12\n",
      "           4       1.00      0.38      0.56        13\n",
      "           6       0.33      0.33      0.33        21\n",
      "           7       0.54      0.60      0.56       121\n",
      "           8       1.00      0.40      0.57         5\n",
      "           9       0.32      0.34      0.33        47\n",
      "\n",
      "    accuracy                           0.45       499\n",
      "   macro avg       0.48      0.35      0.39       499\n",
      "weighted avg       0.46      0.45      0.45       499\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.43259557344064387\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.49      0.50       118\n",
      "           1       0.36      0.46      0.41       117\n",
      "          10       0.12      0.12      0.12        25\n",
      "           2       0.36      0.20      0.26        20\n",
      "           3       0.17      0.09      0.12        11\n",
      "           4       0.88      0.58      0.70        12\n",
      "           6       0.38      0.38      0.38        21\n",
      "           7       0.51      0.55      0.53       121\n",
      "           8       1.00      0.20      0.33         5\n",
      "           9       0.41      0.26      0.32        47\n",
      "\n",
      "    accuracy                           0.43       497\n",
      "   macro avg       0.47      0.33      0.37       497\n",
      "weighted avg       0.44      0.43      0.43       497\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.42943548387096775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.51      0.50       118\n",
      "           1       0.32      0.33      0.33       116\n",
      "          10       0.29      0.32      0.30        25\n",
      "           2       0.46      0.30      0.36        20\n",
      "           3       0.40      0.18      0.25        11\n",
      "           4       0.56      0.42      0.48        12\n",
      "           6       0.56      0.43      0.49        21\n",
      "           7       0.46      0.60      0.52       121\n",
      "           8       0.33      0.20      0.25         5\n",
      "           9       0.48      0.26      0.33        47\n",
      "\n",
      "    accuracy                           0.43       496\n",
      "   macro avg       0.43      0.35      0.38       496\n",
      "weighted avg       0.43      0.43      0.42       496\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.4222222222222222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.62      0.55       117\n",
      "           1       0.38      0.41      0.39       116\n",
      "          10       0.24      0.32      0.28        25\n",
      "           2       0.43      0.15      0.22        20\n",
      "           3       0.30      0.27      0.29        11\n",
      "           4       0.50      0.17      0.25        12\n",
      "           6       0.33      0.19      0.24        21\n",
      "           7       0.43      0.46      0.45       121\n",
      "           8       1.00      0.40      0.57         5\n",
      "           9       0.42      0.23      0.30        47\n",
      "\n",
      "    accuracy                           0.42       495\n",
      "   macro avg       0.45      0.32      0.35       495\n",
      "weighted avg       0.42      0.42      0.41       495\n",
      "\n",
      "--------------------------------------------------\n",
      "accuracy: 43.27% (+/- 1.17%)\n",
      "precision: 46.91% (+/- 2.37%)\n",
      "recall: 33.80% (+/- 1.26%)\n",
      "f1 score: 37.13% (+/- 1.22%)\n"
     ]
    }
   ],
   "source": [
    "logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
    "               ])\n",
    "lr_cv(split, df['cleantext'].values.astype(str), df['label'].values.astype(str), logreg, avg_method)\n",
    "\n",
    "#logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.4578313253012048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.57      0.54       185\n",
      "           1       0.44      0.49      0.46       188\n",
      "          10       0.23      0.31      0.26        32\n",
      "           2       0.38      0.22      0.28        27\n",
      "           3       0.20      0.05      0.08        20\n",
      "           4       0.67      0.35      0.46        17\n",
      "           6       0.45      0.31      0.37        32\n",
      "           7       0.49      0.54      0.51       174\n",
      "           8       1.00      0.12      0.22         8\n",
      "           9       0.37      0.27      0.31        64\n",
      "\n",
      "    accuracy                           0.46       747\n",
      "   macro avg       0.47      0.32      0.35       747\n",
      "weighted avg       0.46      0.46      0.45       747\n",
      "\n",
      "Wall time: 58 ms\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "# y_pred = logreg.predict(X_test)\n",
    "\n",
    "# print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec and Logistic Regression\n",
    "\n",
    "### note:\n",
    "Word2vec is a type of mapping that allows words with similar meaning to have similar vector representation &rarr;\n",
    "\n",
    "use surrounding words to represent the target words with a Neural Network whose hidden layer encodes the word representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "wv = gensim.models.KeyedVectors.load_word2vec_format(\"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\", binary=True)\n",
    "wv.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Memorial_Hospital',\n",
       " 'Seniors',\n",
       " 'memorandum',\n",
       " 'elephant',\n",
       " 'Trump',\n",
       " 'Census',\n",
       " 'pilgrims',\n",
       " 'De',\n",
       " 'Dogs',\n",
       " '###-####_ext',\n",
       " 'chaotic',\n",
       " 'forgive',\n",
       " 'scholar',\n",
       " 'Lottery',\n",
       " 'decreasing',\n",
       " 'Supervisor',\n",
       " 'fundamentally',\n",
       " 'Fitness',\n",
       " 'abundance',\n",
       " 'Hold']"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import islice\n",
    "list(islice(wv.vocab, 13030, 13050))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of word averaging\n",
    "https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_averaging(wv, words):\n",
    "    all_words, mean = set(), []\n",
    "    \n",
    "    for word in words:\n",
    "        if isinstance(word, np.ndarray):\n",
    "            mean.append(word)\n",
    "        elif word in wv.vocab:\n",
    "            mean.append(wv.syn0norm[wv.vocab[word].index])\n",
    "            all_words.add(wv.vocab[word].index)\n",
    "\n",
    "    if not mean:\n",
    "        logging.warning(\"cannot compute similarity with no input %s\", words)\n",
    "        # FIXME: remove these examples in pre-processing\n",
    "        return np.zeros(wv.vector_size,)\n",
    "\n",
    "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
    "    return mean\n",
    "\n",
    "def  word_averaging_list(wv, text_list):\n",
    "    return np.vstack([word_averaging(wv, post) for post in text_list ])\n",
    "\n",
    "def w2v_tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text, language='english'):\n",
    "        for word in nltk.word_tokenize(sent, language='english'):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train, test = train_test_split(df, test_size=0.3, random_state = 42)\n",
    "\n",
    "test_tokenized = test.apply(lambda r: w2v_tokenize_text(r['cleantext']), axis=1).values\n",
    "train_tokenized = train.apply(lambda r: w2v_tokenize_text(r['cleantext']), axis=1).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `syn0norm` (Attribute will be removed in 4.0.0, use self.vectors_norm instead).\n",
      "  \n",
      "W0812 01:16:17.230739 15920 <ipython-input-230-63760c81b177>:12] cannot compute similarity with no input []\n",
      "W0812 01:16:17.636733 15920 <ipython-input-230-63760c81b177>:12] cannot compute similarity with no input ['getmodern']\n",
      "W0812 01:16:17.721738 15920 <ipython-input-230-63760c81b177>:12] cannot compute similarity with no input []\n",
      "W0812 01:16:18.054777 15920 <ipython-input-230-63760c81b177>:12] cannot compute similarity with no input []\n"
     ]
    }
   ],
   "source": [
    "X_train_word_average = word_averaging_list(wv,train_tokenized)\n",
    "X_test_word_average = word_averaging_list(wv,test_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logistic regression classifiers performs on these word-averaging document features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "\n",
    "#can't work\n",
    "# lr_cv(split, X_train_word_average, X_test_word_average, logreg, avg_method)\n",
    "\n",
    "logreg = logreg.fit(X_train_word_average, train['label'])\n",
    "y_pred = logreg.predict(X_test_word_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.42971887550200805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.47      0.49       192\n",
      "           1       0.42      0.34      0.38       202\n",
      "          10       0.13      0.27      0.18        26\n",
      "           2       0.39      0.41      0.40        27\n",
      "           3       0.11      0.18      0.13        11\n",
      "           4       0.67      0.30      0.41        20\n",
      "           6       0.46      0.46      0.46        28\n",
      "           7       0.49      0.60      0.54       164\n",
      "           8       0.33      0.25      0.29         8\n",
      "           9       0.36      0.30      0.33        69\n",
      "\n",
      "    accuracy                           0.43       747\n",
      "   macro avg       0.39      0.36      0.36       747\n",
      "weighted avg       0.45      0.43      0.43       747\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, test.label))\n",
    "print(classification_report(test.label, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2vec and Logistic Regression¶\n",
    "\n",
    "## reference:\n",
    "### -what is Doc2vec\n",
    "https://medium.com/scaleabout/a-gentle-introduction-to-doc2vec-db3e8c0cce5e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "from sklearn import utils\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas(desc=\"progress-bar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_sentences(corpus, label_type):\n",
    "    \"\"\"\n",
    "    Gensim's Doc2Vec implementation requires each document/paragraph to have a label associated with it.\n",
    "    We do this by using the TaggedDocument method. The format will be \"TRAIN_i\" or \"TEST_i\" where \"i\" is\n",
    "    a dummy index of the post.\n",
    "    \"\"\"\n",
    "    labeled = []\n",
    "    for i, v in enumerate(corpus):\n",
    "        label = label_type + '_' + str(i)\n",
    "        labeled.append(TaggedDocument(v.split(), [label]))\n",
    "    return labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = label_sentences(X_train, 'Train')\n",
    "X_test = label_sentences(X_test, 'Test')\n",
    "all_data = X_train + X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['love', 'see', 'how', 'our', 'tech', 'help', 'customer', 'like', 'the', 'boston', 'aim', 'for', 'the', 'fence'], tags=['Train_0']),\n",
       " TaggedDocument(words=['meet', 'the', 'inspiron', 'series', 'in', 'special', 'edition'], tags=['Train_1'])]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\gensim\\models\\base_any2vec.py:743: UserWarning: C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  \"C extension not loaded, training will be slow. \"\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2489/2489 [00:00<00:00, 1242812.22it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, min_count=1, alpha=0.065, min_alpha=0.065)\n",
    "model_dbow.build_vocab([x for x in tqdm(all_data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 2489/2489 [00:00<00:00, 828541.48it/s]\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0811 23:05:24.536418 15920 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2489/2489 [00:00<00:00, 497432.82it/s]\n",
      "W0811 23:05:45.475617 15920 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2489/2489 [00:00<00:00, 830717.17it/s]\n",
      "W0811 23:06:06.144796 15920 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2489/2489 [00:00<00:00, 2495129.70it/s]\n",
      "W0811 23:06:25.971814 15920 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2489/2489 [00:00<00:00, 500173.57it/s]\n",
      "W0811 23:06:47.698160 15920 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2489/2489 [00:00<00:00, 2473844.23it/s]\n",
      "W0811 23:07:09.301450 15920 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2489/2489 [00:00<00:00, 829397.21it/s]\n",
      "W0811 23:07:30.371706 15920 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2489/2489 [00:00<00:00, 2490962.22it/s]\n",
      "W0811 23:07:51.621932 15920 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2489/2489 [00:00<00:00, 497598.79it/s]\n",
      "W0811 23:08:11.036906 15920 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2489/2489 [00:00<00:00, 1254008.73it/s]\n",
      "W0811 23:08:29.901792 15920 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2489/2489 [00:00<00:00, 830188.68it/s]\n",
      "W0811 23:08:50.698978 15920 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2489/2489 [00:00<00:00, 1221151.32it/s]\n",
      "W0811 23:09:13.006388 15920 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2489/2489 [00:00<00:00, 1247415.78it/s]\n",
      "W0811 23:09:31.287186 15920 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2489/2489 [00:00<00:00, 2484441.37it/s]\n",
      "W0811 23:09:50.566138 15920 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2489/2489 [00:00<00:00, 829529.02it/s]\n",
      "W0811 23:10:09.340018 15920 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2489/2489 [00:00<00:00, 829397.21it/s]\n",
      "W0811 23:10:29.813146 15920 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2489/2489 [00:00<00:00, 2390023.50it/s]\n",
      "W0811 23:10:50.325332 15920 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2489/2489 [00:00<00:00, 622629.13it/s]\n",
      "W0811 23:11:09.767300 15920 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2489/2489 [00:00<00:00, 2493937.57it/s]\n",
      "W0811 23:11:30.297409 15920 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2489/2489 [00:00<00:00, 828212.82it/s]\n",
      "W0811 23:11:48.597214 15920 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2489/2489 [00:00<00:00, 1240449.46it/s]\n",
      "W0811 23:12:07.745637 15920 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2489/2489 [00:00<00:00, 828475.73it/s]\n",
      "W0811 23:12:26.124684 15920 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2489/2489 [00:00<00:00, 819050.89it/s]\n",
      "W0811 23:12:42.970260 15920 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2489/2489 [00:00<00:00, 1243256.24it/s]\n",
      "W0811 23:13:03.030329 15920 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2489/2489 [00:00<00:00, 1242664.28it/s]\n",
      "W0811 23:13:22.427676 15920 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2489/2489 [00:00<00:00, 1241629.72it/s]\n",
      "W0811 23:13:41.409546 15920 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2489/2489 [00:00<00:00, 1253105.59it/s]\n",
      "W0811 23:14:01.700657 15920 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2489/2489 [00:00<00:00, 830518.91it/s]\n",
      "W0811 23:14:22.637857 15920 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2489/2489 [00:00<00:00, 829265.44it/s]\n",
      "W0811 23:14:45.100297 15920 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2489/2489 [00:00<00:00, 2493937.57it/s]\n",
      "W0811 23:15:06.048424 15920 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(all_data)]), total_examples=len(all_data), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(model, corpus_size, vectors_size, vectors_type):\n",
    "    \"\"\"\n",
    "    Get vectors from trained doc2vec model\n",
    "    :param doc2vec_model: Trained Doc2Vec model\n",
    "    :param corpus_size: Size of the data\n",
    "    :param vectors_size: Size of the embedding vectors\n",
    "    :param vectors_type: Training or Testing vectors\n",
    "    :return: list of vectors\n",
    "    \"\"\"\n",
    "    vectors = np.zeros((corpus_size, vectors_size))\n",
    "    for i in range(0, corpus_size):\n",
    "        prefix = vectors_type + '_' + str(i)\n",
    "        vectors[i] = model.docvecs[prefix]\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train_vectors_dbow = get_vectors(model_dbow, len(X_train), 300, 'Train')\n",
    "test_vectors_dbow = get_vectors(model_dbow, len(X_test), 300, 'Test')\n",
    "\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "\n",
    "#\n",
    "logreg.fit(train_vectors_dbow, y_train)\n",
    "\n",
    "logreg = logreg.fit(train_vectors_dbow, y_train)\n",
    "y_pred = logreg.predict(test_vectors_dbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.3855421686746988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.49      0.52       185\n",
      "           1       0.42      0.36      0.38       188\n",
      "          10       0.08      0.16      0.11        32\n",
      "           2       0.29      0.37      0.33        27\n",
      "           3       0.17      0.25      0.20        20\n",
      "           4       0.12      0.24      0.16        17\n",
      "           6       0.17      0.25      0.20        32\n",
      "           7       0.52      0.49      0.51       174\n",
      "           8       0.14      0.25      0.18         8\n",
      "           9       0.26      0.19      0.22        64\n",
      "\n",
      "    accuracy                           0.39       747\n",
      "   macro avg       0.27      0.30      0.28       747\n",
      "weighted avg       0.42      0.39      0.40       747\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fixing imbalance with oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import ADASYN, SMOTE, RandomOverSampler\n",
    "\n",
    "ROS_pipeline = make_pipeline(tvec, RandomOverSampler(random_state=777),lr)\n",
    "SMOTE_pipeline = make_pipeline(tvec, SMOTE(random_state=777),lr)\n",
    "ADASYN_pipeline = make_pipeline(tvec, ADASYN(ratio='minority',random_state=777),lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. RandomOverSampler¶\n",
    "Random over-sampling is simply a process of repeating some samples of the minority class and balance the number of samples between classes in the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5298804780876494\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.64      0.65       118\n",
      "           1       0.53      0.42      0.47       117\n",
      "          10       0.28      0.40      0.33        25\n",
      "           2       0.33      0.50      0.40        20\n",
      "           3       0.40      0.33      0.36        12\n",
      "           4       0.89      0.62      0.73        13\n",
      "           6       0.67      0.36      0.47        22\n",
      "           7       0.52      0.69      0.59       121\n",
      "           8       0.67      0.33      0.44         6\n",
      "           9       0.46      0.35      0.40        48\n",
      "\n",
      "    accuracy                           0.53       502\n",
      "   macro avg       0.54      0.46      0.48       502\n",
      "weighted avg       0.55      0.53      0.53       502\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5130260521042084\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.58      0.64       118\n",
      "           1       0.53      0.47      0.50       117\n",
      "          10       0.23      0.12      0.16        25\n",
      "           2       0.33      0.50      0.40        20\n",
      "           3       0.10      0.08      0.09        12\n",
      "           4       0.56      0.38      0.45        13\n",
      "           6       0.27      0.19      0.22        21\n",
      "           7       0.52      0.74      0.61       121\n",
      "           8       0.67      0.40      0.50         5\n",
      "           9       0.38      0.36      0.37        47\n",
      "\n",
      "    accuracy                           0.51       499\n",
      "   macro avg       0.43      0.38      0.39       499\n",
      "weighted avg       0.51      0.51      0.50       499\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.4909456740442656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.53      0.57       118\n",
      "           1       0.46      0.40      0.43       117\n",
      "          10       0.09      0.08      0.08        25\n",
      "           2       0.27      0.35      0.30        20\n",
      "           3       0.20      0.18      0.19        11\n",
      "           4       0.56      0.42      0.48        12\n",
      "           6       0.47      0.43      0.45        21\n",
      "           7       0.55      0.81      0.65       121\n",
      "           8       1.00      0.20      0.33         5\n",
      "           9       0.39      0.23      0.29        47\n",
      "\n",
      "    accuracy                           0.49       497\n",
      "   macro avg       0.46      0.36      0.38       497\n",
      "weighted avg       0.49      0.49      0.48       497\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5201612903225806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.60      0.60       118\n",
      "           1       0.55      0.39      0.45       116\n",
      "          10       0.38      0.48      0.42        25\n",
      "           2       0.45      0.70      0.55        20\n",
      "           3       0.25      0.18      0.21        11\n",
      "           4       0.56      0.42      0.48        12\n",
      "           6       0.50      0.38      0.43        21\n",
      "           7       0.50      0.69      0.58       121\n",
      "           8       0.33      0.20      0.25         5\n",
      "           9       0.57      0.34      0.43        47\n",
      "\n",
      "    accuracy                           0.52       496\n",
      "   macro avg       0.47      0.44      0.44       496\n",
      "weighted avg       0.53      0.52      0.51       496\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5070707070707071\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.62      0.58       117\n",
      "           1       0.55      0.48      0.52       116\n",
      "          10       0.20      0.28      0.23        25\n",
      "           2       0.41      0.45      0.43        20\n",
      "           3       0.18      0.18      0.18        11\n",
      "           4       0.88      0.58      0.70        12\n",
      "           6       0.43      0.14      0.21        21\n",
      "           7       0.54      0.69      0.60       121\n",
      "           8       0.50      0.20      0.29         5\n",
      "           9       0.45      0.21      0.29        47\n",
      "\n",
      "    accuracy                           0.51       495\n",
      "   macro avg       0.47      0.38      0.40       495\n",
      "weighted avg       0.51      0.51      0.50       495\n",
      "\n",
      "--------------------------------------------------\n",
      "accuracy: 51.22% (+/- 1.31%)\n",
      "precision: 47.36% (+/- 3.67%)\n",
      "recall: 40.67% (+/- 3.80%)\n",
      "f1 score: 42.02% (+/- 3.79%)\n"
     ]
    }
   ],
   "source": [
    "lr_cv(split, df['cleantext'].values.astype(str), df['label'].values.astype(str), ROS_pipeline, avg_method)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. SMOTE (Synthetic Minority Over-Sampling Technique\n",
    "SMOTE is an over-sampling approach in which the minority class is over-sampled by creating “synthetic” examples rather than by over-sampling with replacement.\n",
    "What this means is that when SMOTE creates a new synthetic data, it will choose one data to copy, and look at its k nearest neighbours. Then, on feature space, it will create random values in feature space that is between the original sample and its neighbours.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5318725099601593\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.64      0.67       118\n",
      "           1       0.55      0.43      0.48       117\n",
      "          10       0.29      0.44      0.35        25\n",
      "           2       0.28      0.50      0.36        20\n",
      "           3       0.33      0.25      0.29        12\n",
      "           4       1.00      0.54      0.70        13\n",
      "           6       0.57      0.36      0.44        22\n",
      "           7       0.54      0.69      0.60       121\n",
      "           8       0.67      0.33      0.44         6\n",
      "           9       0.42      0.35      0.39        48\n",
      "\n",
      "    accuracy                           0.53       502\n",
      "   macro avg       0.53      0.45      0.47       502\n",
      "weighted avg       0.55      0.53      0.53       502\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5090180360721442\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.59      0.62       118\n",
      "           1       0.51      0.45      0.48       117\n",
      "          10       0.27      0.16      0.20        25\n",
      "           2       0.29      0.50      0.37        20\n",
      "           3       0.17      0.08      0.11        12\n",
      "           4       0.71      0.38      0.50        13\n",
      "           6       0.28      0.24      0.26        21\n",
      "           7       0.53      0.72      0.61       121\n",
      "           8       0.67      0.40      0.50         5\n",
      "           9       0.40      0.36      0.38        47\n",
      "\n",
      "    accuracy                           0.51       499\n",
      "   macro avg       0.45      0.39      0.40       499\n",
      "weighted avg       0.51      0.51      0.50       499\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.4909456740442656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.50      0.55       118\n",
      "           1       0.46      0.41      0.43       117\n",
      "          10       0.14      0.12      0.13        25\n",
      "           2       0.28      0.35      0.31        20\n",
      "           3       0.22      0.18      0.20        11\n",
      "           4       0.71      0.42      0.53        12\n",
      "           6       0.48      0.48      0.48        21\n",
      "           7       0.54      0.79      0.64       121\n",
      "           8       1.00      0.20      0.33         5\n",
      "           9       0.38      0.28      0.32        47\n",
      "\n",
      "    accuracy                           0.49       497\n",
      "   macro avg       0.48      0.37      0.39       497\n",
      "weighted avg       0.49      0.49      0.48       497\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5201612903225806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.60      0.59       118\n",
      "           1       0.53      0.39      0.45       116\n",
      "          10       0.30      0.44      0.35        25\n",
      "           2       0.48      0.70      0.57        20\n",
      "           3       0.40      0.18      0.25        11\n",
      "           4       0.56      0.42      0.48        12\n",
      "           6       0.53      0.38      0.44        21\n",
      "           7       0.51      0.69      0.59       121\n",
      "           8       0.33      0.20      0.25         5\n",
      "           9       0.61      0.36      0.45        47\n",
      "\n",
      "    accuracy                           0.52       496\n",
      "   macro avg       0.48      0.44      0.44       496\n",
      "weighted avg       0.53      0.52      0.51       496\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5070707070707071\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.62      0.59       117\n",
      "           1       0.57      0.44      0.50       116\n",
      "          10       0.26      0.36      0.31        25\n",
      "           2       0.32      0.45      0.38        20\n",
      "           3       0.17      0.18      0.17        11\n",
      "           4       0.88      0.58      0.70        12\n",
      "           6       0.57      0.19      0.29        21\n",
      "           7       0.54      0.69      0.61       121\n",
      "           8       0.33      0.20      0.25         5\n",
      "           9       0.41      0.26      0.32        47\n",
      "\n",
      "    accuracy                           0.51       495\n",
      "   macro avg       0.46      0.40      0.41       495\n",
      "weighted avg       0.52      0.51      0.50       495\n",
      "\n",
      "--------------------------------------------------\n",
      "accuracy: 51.18% (+/- 1.37%)\n",
      "precision: 48.23% (+/- 2.93%)\n",
      "recall: 40.98% (+/- 3.04%)\n",
      "f1 score: 42.41% (+/- 2.93%)\n"
     ]
    }
   ],
   "source": [
    "lr_cv(split, df['cleantext'].values.astype(str), df['label'].values.astype(str), SMOTE_pipeline, avg_method)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fixing imbalance with downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss, RandomUnderSampler\n",
    "\n",
    "RUS_pipeline = make_pipeline(tvec, RandomUnderSampler(random_state=777),lr)\n",
    "NM1_pipeline = make_pipeline(tvec, NearMiss(ratio='not minority',random_state=777, version = 1),lr)\n",
    "NM2_pipeline = make_pipeline(tvec, NearMiss(ratio='not minority',random_state=777, version = 2),lr)\n",
    "NM3_pipeline = make_pipeline(tvec, NearMiss(ratio='not minority',random_state=777, version = 3, n_neighbors_ver3=4),lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. RandomUnderSampler¶\n",
    "with downsampling, we try to reduce the data of majority class, so that the data classes are balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.26693227091633465\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.26      0.35       118\n",
      "           1       0.27      0.09      0.13       117\n",
      "          10       0.21      0.36      0.26        25\n",
      "           2       0.23      0.50      0.31        20\n",
      "           3       0.12      0.58      0.19        12\n",
      "           4       0.25      0.69      0.37        13\n",
      "           6       0.17      0.32      0.22        22\n",
      "           7       0.44      0.25      0.32       121\n",
      "           8       0.04      0.50      0.08         6\n",
      "           9       0.38      0.38      0.38        48\n",
      "\n",
      "    accuracy                           0.27       502\n",
      "   macro avg       0.26      0.39      0.26       502\n",
      "weighted avg       0.37      0.27      0.28       502\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.32665330661322645\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.34      0.43       118\n",
      "           1       0.47      0.26      0.33       117\n",
      "          10       0.17      0.16      0.17        25\n",
      "           2       0.17      0.35      0.23        20\n",
      "           3       0.09      0.25      0.14        12\n",
      "           4       0.38      0.46      0.41        13\n",
      "           6       0.16      0.33      0.21        21\n",
      "           7       0.49      0.42      0.45       121\n",
      "           8       0.06      0.80      0.12         5\n",
      "           9       0.26      0.23      0.25        47\n",
      "\n",
      "    accuracy                           0.33       499\n",
      "   macro avg       0.28      0.36      0.27       499\n",
      "weighted avg       0.43      0.33      0.35       499\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.3158953722334004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.33      0.44       118\n",
      "           1       0.50      0.23      0.32       117\n",
      "          10       0.11      0.16      0.13        25\n",
      "           2       0.21      0.55      0.31        20\n",
      "           3       0.10      0.45      0.16        11\n",
      "           4       0.55      0.50      0.52        12\n",
      "           6       0.23      0.71      0.34        21\n",
      "           7       0.48      0.34      0.40       121\n",
      "           8       0.06      0.60      0.11         5\n",
      "           9       0.20      0.13      0.16        47\n",
      "\n",
      "    accuracy                           0.32       497\n",
      "   macro avg       0.31      0.40      0.29       497\n",
      "weighted avg       0.45      0.32      0.34       497\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.26814516129032256\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.29      0.37       118\n",
      "           1       0.34      0.17      0.23       116\n",
      "          10       0.11      0.24      0.15        25\n",
      "           2       0.19      0.65      0.30        20\n",
      "           3       0.08      0.18      0.11        11\n",
      "           4       0.50      0.42      0.45        12\n",
      "           6       0.17      0.38      0.24        21\n",
      "           7       0.44      0.26      0.32       121\n",
      "           8       0.05      0.60      0.10         5\n",
      "           9       0.26      0.23      0.24        47\n",
      "\n",
      "    accuracy                           0.27       496\n",
      "   macro avg       0.27      0.34      0.25       496\n",
      "weighted avg       0.37      0.27      0.29       496\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.26464646464646463\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.31      0.40       117\n",
      "           1       0.33      0.09      0.15       116\n",
      "          10       0.17      0.28      0.22        25\n",
      "           2       0.15      0.40      0.21        20\n",
      "           3       0.10      0.55      0.17        11\n",
      "           4       0.37      0.58      0.45        12\n",
      "           6       0.14      0.33      0.20        21\n",
      "           7       0.47      0.31      0.37       121\n",
      "           8       0.07      0.80      0.12         5\n",
      "           9       0.24      0.17      0.20        47\n",
      "\n",
      "    accuracy                           0.26       495\n",
      "   macro avg       0.26      0.38      0.25       495\n",
      "weighted avg       0.38      0.26      0.28       495\n",
      "\n",
      "--------------------------------------------------\n",
      "accuracy: 28.85% (+/- 2.70%)\n",
      "precision: 27.70% (+/- 1.84%)\n",
      "recall: 37.56% (+/- 2.15%)\n",
      "f1 score: 26.46% (+/- 1.46%)\n"
     ]
    }
   ],
   "source": [
    "lr_cv(split, df['cleantext'].values.astype(str), df['label'].values.astype(str), RUS_pipeline, avg_method)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. NearMiss\n",
    "NearMiss adds some heuristic rules to select samples. NearMiss implements 3 different types of heuristic which can be selected with the parameter version. NearMiss heuristic rules are based on nearest neighbors algorithm.\" http://contrib.scikit-learn.org/imbalanced-learn/stable/under_sampling.html#controlled-under-sampling\n",
    "\n",
    "##### 1. NearMiss-1\n",
    "In NearMiss-1, those points from majority class are retained whose mean distance to the k nearest points in minority class is lowest. Which means it will keep the points of majority class that's similar to the minority class.\n",
    "\n",
    "##### 2. NearMiss-2\n",
    "In contrast to NearMiss-1, NearMiss-2 keeps those points from the majority class whose mean distance to the k farthest points in minority class is lowest. In other words, it will keep the points of majority class that's most different to the minority class.\n",
    "\n",
    "##### 3. NearMiss-3\n",
    "The final NearMiss variant, NearMiss-3 selects k nearest neighbours in majority class for every point in the minority class. In this case, the undersampling ratio is directly controlled by k. For example, if we set k to be 4, then NearMiss-3 will choose 4 nearest neighbours of every minority class entry.\n",
    "\n",
    "author's doubt: One thing is that what kind of filtering it applies when all the data selected with n_neighbors_ver3 parameter is more than the minority class. After applying NearMiss-3, the dataset is perfectly balanced. However, if the algorithm simply chooses the nearest neighbour according to the n_neighbors_ver3 parameter, why does it end up with the exact same number of entries for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.1852589641434263\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.06      0.09       118\n",
      "           1       0.35      0.07      0.11       117\n",
      "          10       0.30      0.32      0.31        25\n",
      "           2       0.19      0.45      0.27        20\n",
      "           3       0.12      0.17      0.14        12\n",
      "           4       0.64      0.54      0.58        13\n",
      "           6       0.09      0.73      0.16        22\n",
      "           7       0.78      0.15      0.25       121\n",
      "           8       0.04      0.33      0.07         6\n",
      "           9       0.16      0.33      0.22        48\n",
      "\n",
      "    accuracy                           0.19       502\n",
      "   macro avg       0.29      0.31      0.22       502\n",
      "weighted avg       0.39      0.19      0.18       502\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.218436873747495\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.27      0.34       118\n",
      "           1       0.18      0.02      0.03       117\n",
      "          10       0.27      0.16      0.20        25\n",
      "           2       0.16      0.55      0.25        20\n",
      "           3       0.12      0.25      0.17        12\n",
      "           4       0.35      0.46      0.40        13\n",
      "           6       0.09      0.52      0.15        21\n",
      "           7       0.65      0.17      0.26       121\n",
      "           8       0.08      0.60      0.14         5\n",
      "           9       0.18      0.36      0.24        47\n",
      "\n",
      "    accuracy                           0.22       499\n",
      "   macro avg       0.25      0.34      0.22       499\n",
      "weighted avg       0.36      0.22      0.21       499\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.2193158953722334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.19      0.26       118\n",
      "           1       0.37      0.06      0.10       117\n",
      "          10       0.18      0.12      0.14        25\n",
      "           2       0.15      0.35      0.21        20\n",
      "           3       0.09      0.27      0.13        11\n",
      "           4       0.88      0.58      0.70        12\n",
      "           6       0.06      0.43      0.11        21\n",
      "           7       0.55      0.25      0.34       121\n",
      "           8       0.06      0.40      0.10         5\n",
      "           9       0.21      0.38      0.27        47\n",
      "\n",
      "    accuracy                           0.22       497\n",
      "   macro avg       0.29      0.30      0.24       497\n",
      "weighted avg       0.38      0.22      0.24       497\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.2399193548387097\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.23      0.33       118\n",
      "           1       0.38      0.12      0.18       116\n",
      "          10       0.30      0.28      0.29        25\n",
      "           2       0.16      0.55      0.25        20\n",
      "           3       0.17      0.18      0.17        11\n",
      "           4       0.40      0.33      0.36        12\n",
      "           6       0.07      0.52      0.13        21\n",
      "           7       0.62      0.21      0.31       121\n",
      "           8       0.07      0.40      0.12         5\n",
      "           9       0.19      0.34      0.24        47\n",
      "\n",
      "    accuracy                           0.24       496\n",
      "   macro avg       0.30      0.32      0.24       496\n",
      "weighted avg       0.44      0.24      0.26       496\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.21818181818181817\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.14      0.20       117\n",
      "           1       0.22      0.06      0.09       116\n",
      "          10       0.23      0.32      0.27        25\n",
      "           2       0.16      0.45      0.24        20\n",
      "           3       0.14      0.27      0.19        11\n",
      "           4       0.60      0.50      0.55        12\n",
      "           6       0.08      0.67      0.14        21\n",
      "           7       0.84      0.22      0.35       121\n",
      "           8       0.08      0.40      0.13         5\n",
      "           9       0.26      0.34      0.29        47\n",
      "\n",
      "    accuracy                           0.22       495\n",
      "   macro avg       0.30      0.34      0.24       495\n",
      "weighted avg       0.41      0.22      0.23       495\n",
      "\n",
      "--------------------------------------------------\n",
      "accuracy: 21.62% (+/- 1.75%)\n",
      "precision: 28.57% (+/- 1.72%)\n",
      "recall: 32.16% (+/- 1.29%)\n",
      "f1 score: 23.21% (+/- 1.08%)\n"
     ]
    }
   ],
   "source": [
    "lr_cv(split, df['cleantext'].values.astype(str), df['label'].values.astype(str), NM1_pipeline, avg_method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.27689243027888444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.30      0.37       118\n",
      "           1       0.44      0.19      0.26       117\n",
      "          10       0.15      0.20      0.17        25\n",
      "           2       0.17      0.40      0.24        20\n",
      "           3       0.12      0.58      0.19        12\n",
      "           4       0.23      0.77      0.35        13\n",
      "           6       0.17      0.55      0.26        22\n",
      "           7       0.51      0.23      0.32       121\n",
      "           8       0.10      0.50      0.16         6\n",
      "           9       0.24      0.19      0.21        48\n",
      "\n",
      "    accuracy                           0.28       502\n",
      "   macro avg       0.26      0.39      0.25       502\n",
      "weighted avg       0.39      0.28      0.29       502\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.23246492985971945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.23      0.34       118\n",
      "           1       0.35      0.14      0.20       117\n",
      "          10       0.12      0.20      0.15        25\n",
      "           2       0.24      0.60      0.35        20\n",
      "           3       0.10      0.25      0.14        12\n",
      "           4       0.13      0.62      0.22        13\n",
      "           6       0.08      0.29      0.12        21\n",
      "           7       0.48      0.21      0.29       121\n",
      "           8       0.07      0.80      0.13         5\n",
      "           9       0.23      0.21      0.22        47\n",
      "\n",
      "    accuracy                           0.23       499\n",
      "   macro avg       0.24      0.35      0.22       499\n",
      "weighted avg       0.40      0.23      0.25       499\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.2676056338028169\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.16      0.25       118\n",
      "           1       0.42      0.24      0.30       117\n",
      "          10       0.06      0.20      0.09        25\n",
      "           2       0.25      0.50      0.33        20\n",
      "           3       0.17      0.64      0.26        11\n",
      "           4       0.21      0.58      0.31        12\n",
      "           6       0.12      0.38      0.18        21\n",
      "           7       0.54      0.27      0.36       121\n",
      "           8       0.07      0.40      0.12         5\n",
      "           9       0.33      0.30      0.31        47\n",
      "\n",
      "    accuracy                           0.27       497\n",
      "   macro avg       0.27      0.37      0.25       497\n",
      "weighted avg       0.42      0.27      0.29       497\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.2782258064516129\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.34      0.43       118\n",
      "           1       0.38      0.19      0.25       116\n",
      "          10       0.06      0.12      0.08        25\n",
      "           2       0.19      0.45      0.27        20\n",
      "           3       0.06      0.27      0.10        11\n",
      "           4       0.16      0.75      0.26        12\n",
      "           6       0.22      0.52      0.31        21\n",
      "           7       0.61      0.28      0.38       121\n",
      "           8       0.03      0.20      0.05         5\n",
      "           9       0.20      0.13      0.16        47\n",
      "\n",
      "    accuracy                           0.28       496\n",
      "   macro avg       0.25      0.33      0.23       496\n",
      "weighted avg       0.42      0.28      0.31       496\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.2727272727272727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.36      0.43       117\n",
      "           1       0.31      0.10      0.15       116\n",
      "          10       0.10      0.28      0.14        25\n",
      "           2       0.23      0.45      0.30        20\n",
      "           3       0.06      0.18      0.09        11\n",
      "           4       0.19      0.67      0.30        12\n",
      "           6       0.12      0.38      0.18        21\n",
      "           7       0.58      0.29      0.39       121\n",
      "           8       0.07      0.40      0.12         5\n",
      "           9       0.33      0.21      0.26        47\n",
      "\n",
      "    accuracy                           0.27       495\n",
      "   macro avg       0.25      0.33      0.24       495\n",
      "weighted avg       0.40      0.27      0.29       495\n",
      "\n",
      "--------------------------------------------------\n",
      "accuracy: 26.56% (+/- 1.70%)\n",
      "precision: 25.54% (+/- 0.96%)\n",
      "recall: 35.37% (+/- 2.35%)\n",
      "f1 score: 23.75% (+/- 1.46%)\n"
     ]
    }
   ],
   "source": [
    "lr_cv(split, df['cleantext'].values.astype(str), df['label'].values.astype(str), NM2_pipeline, avg_method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.300796812749004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.25      0.33       118\n",
      "           1       0.42      0.21      0.28       117\n",
      "          10       0.18      0.40      0.24        25\n",
      "           2       0.26      0.50      0.34        20\n",
      "           3       0.12      0.25      0.16        12\n",
      "           4       0.20      0.62      0.30        13\n",
      "           6       0.10      0.18      0.13        22\n",
      "           7       0.57      0.41      0.48       121\n",
      "           8       0.09      0.67      0.15         6\n",
      "           9       0.18      0.19      0.18        48\n",
      "\n",
      "    accuracy                           0.30       502\n",
      "   macro avg       0.26      0.37      0.26       502\n",
      "weighted avg       0.40      0.30      0.32       502\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.27054108216432865\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.28      0.36       118\n",
      "           1       0.53      0.15      0.23       117\n",
      "          10       0.07      0.12      0.09        25\n",
      "           2       0.15      0.35      0.21        20\n",
      "           3       0.15      0.58      0.24        12\n",
      "           4       0.19      0.54      0.28        13\n",
      "           6       0.11      0.24      0.15        21\n",
      "           7       0.48      0.38      0.43       121\n",
      "           8       0.10      0.80      0.17         5\n",
      "           9       0.12      0.13      0.12        47\n",
      "\n",
      "    accuracy                           0.27       499\n",
      "   macro avg       0.24      0.36      0.23       499\n",
      "weighted avg       0.40      0.27      0.29       499\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.26961770623742454\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.28      0.35       118\n",
      "           1       0.37      0.15      0.22       117\n",
      "          10       0.00      0.00      0.00        25\n",
      "           2       0.11      0.25      0.15        20\n",
      "           3       0.12      0.36      0.18        11\n",
      "           4       0.23      0.67      0.34        12\n",
      "           6       0.17      0.29      0.21        21\n",
      "           7       0.48      0.39      0.43       121\n",
      "           8       0.07      0.60      0.12         5\n",
      "           9       0.22      0.21      0.22        47\n",
      "\n",
      "    accuracy                           0.27       497\n",
      "   macro avg       0.22      0.32      0.22       497\n",
      "weighted avg       0.36      0.27      0.29       497\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.24798387096774194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.20      0.29       118\n",
      "           1       0.43      0.17      0.25       116\n",
      "          10       0.09      0.16      0.11        25\n",
      "           2       0.14      0.30      0.19        20\n",
      "           3       0.12      0.45      0.19        11\n",
      "           4       0.19      0.58      0.29        12\n",
      "           6       0.15      0.29      0.20        21\n",
      "           7       0.43      0.32      0.37       121\n",
      "           8       0.04      0.40      0.08         5\n",
      "           9       0.17      0.21      0.19        47\n",
      "\n",
      "    accuracy                           0.25       496\n",
      "   macro avg       0.23      0.31      0.21       496\n",
      "weighted avg       0.37      0.25      0.27       496\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.2828282828282828\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.31      0.40       117\n",
      "           1       0.49      0.17      0.25       116\n",
      "          10       0.09      0.20      0.12        25\n",
      "           2       0.19      0.30      0.24        20\n",
      "           3       0.03      0.09      0.05        11\n",
      "           4       0.19      0.75      0.31        12\n",
      "           6       0.11      0.19      0.14        21\n",
      "           7       0.49      0.42      0.45       121\n",
      "           8       0.06      0.60      0.12         5\n",
      "           9       0.14      0.11      0.12        47\n",
      "\n",
      "    accuracy                           0.28       495\n",
      "   macro avg       0.24      0.31      0.22       495\n",
      "weighted avg       0.40      0.28      0.31       495\n",
      "\n",
      "--------------------------------------------------\n",
      "accuracy: 27.44% (+/- 1.73%)\n",
      "precision: 23.72% (+/- 1.28%)\n",
      "recall: 33.33% (+/- 2.35%)\n",
      "f1 score: 22.86% (+/- 1.59%)\n"
     ]
    }
   ],
   "source": [
    "lr_cv(split, df['cleantext'].values.astype(str), df['label'].values.astype(str), NM3_pipeline, avg_method)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the sample number we really use in nm3\n",
    "&rarr; apparently too less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution before NearMiss-3: Counter({'7': 605, '0': 589, '1': 583, '9': 236, '10': 125, '6': 106, '2': 100, '4': 62, '3': 57, '8': 26})\n",
      "Distribution after NearMiss-3: Counter({'0': 26, '1': 26, '10': 26, '2': 26, '3': 26, '4': 26, '6': 26, '7': 26, '8': 26, '9': 26})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "nm3 = NearMiss(ratio='not minority',random_state=777, version=3, n_neighbors_ver3=4)\n",
    "tvec = TfidfVectorizer(stop_words=None, max_features=100000, ngram_range=(1, 3))\n",
    "df_tfidf = tvec.fit_transform( df['cleantext'].values.astype(str))\n",
    "X_res, y_res = nm3.fit_sample(df_tfidf, df['label'].values.astype(str))\n",
    "print('Distribution before NearMiss-3: {}'.format(Counter(df['label'].values.astype(str))))\n",
    "print('Distribution after NearMiss-3: {}'.format(Counter(y_res)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOW with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0812 01:21:49.816171 15920 deprecation_wrapper.py:119] From c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0812 01:21:50.105169 15920 deprecation_wrapper.py:119] From c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0812 01:21:50.183171 15920 deprecation_wrapper.py:119] From c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0812 01:21:50.300170 15920 deprecation_wrapper.py:119] From c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0812 01:21:50.350175 15920 deprecation.py:506] From c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0812 01:21:50.439172 15920 deprecation_wrapper.py:119] From c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0812 01:21:50.512186 15920 deprecation_wrapper.py:119] From c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0812 01:21:50.765176 15920 deprecation.py:323] From c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1567 samples, validate on 175 samples\n",
      "Epoch 1/2\n",
      "1567/1567 [==============================] - ETA: 33s - loss: 2.3209 - acc: 0.06 - ETA: 8s - loss: 2.2649 - acc: 0.1406 - ETA: 5s - loss: 2.2341 - acc: 0.187 - ETA: 4s - loss: 2.2007 - acc: 0.195 - ETA: 3s - loss: 2.1436 - acc: 0.233 - ETA: 2s - loss: 2.0855 - acc: 0.276 - ETA: 2s - loss: 2.0465 - acc: 0.289 - ETA: 1s - loss: 2.0250 - acc: 0.296 - ETA: 1s - loss: 1.9918 - acc: 0.316 - ETA: 1s - loss: 1.9851 - acc: 0.313 - ETA: 1s - loss: 1.9715 - acc: 0.312 - ETA: 0s - loss: 1.9437 - acc: 0.317 - ETA: 0s - loss: 1.9504 - acc: 0.320 - ETA: 0s - loss: 1.9499 - acc: 0.322 - ETA: 0s - loss: 1.9305 - acc: 0.330 - ETA: 0s - loss: 1.9268 - acc: 0.326 - ETA: 0s - loss: 1.9092 - acc: 0.336 - ETA: 0s - loss: 1.8876 - acc: 0.347 - ETA: 0s - loss: 1.8737 - acc: 0.352 - 2s 1ms/step - loss: 1.8744 - acc: 0.3523 - val_loss: 1.6842 - val_acc: 0.4514\n",
      "Epoch 2/2\n",
      "1567/1567 [==============================] - ETA: 1s - loss: 1.4412 - acc: 0.500 - ETA: 1s - loss: 1.5380 - acc: 0.552 - ETA: 1s - loss: 1.5755 - acc: 0.525 - ETA: 0s - loss: 1.5577 - acc: 0.527 - ETA: 0s - loss: 1.5154 - acc: 0.536 - ETA: 0s - loss: 1.5017 - acc: 0.533 - ETA: 0s - loss: 1.5289 - acc: 0.520 - ETA: 0s - loss: 1.5116 - acc: 0.525 - ETA: 0s - loss: 1.5181 - acc: 0.525 - ETA: 0s - loss: 1.4973 - acc: 0.536 - ETA: 0s - loss: 1.4914 - acc: 0.536 - ETA: 0s - loss: 1.4741 - acc: 0.544 - ETA: 0s - loss: 1.4703 - acc: 0.542 - ETA: 0s - loss: 1.4710 - acc: 0.535 - ETA: 0s - loss: 1.4689 - acc: 0.530 - ETA: 0s - loss: 1.4608 - acc: 0.532 - ETA: 0s - loss: 1.4611 - acc: 0.527 - 1s 671us/step - loss: 1.4565 - acc: 0.5303 - val_loss: 1.5218 - val_acc: 0.4971\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import utils\n",
    "\n",
    "train_size = int(len(df) * .7)\n",
    "train_posts = df['cleantext'][:train_size]\n",
    "train_tags = df['label'][:train_size]\n",
    "\n",
    "test_posts = df['cleantext'][train_size:]\n",
    "test_tags = df['label'][train_size:]\n",
    "\n",
    "max_words = 1000\n",
    "tokenize = text.Tokenizer(num_words=max_words, char_level=False)\n",
    "tokenize.fit_on_texts(train_posts) # only fit on train\n",
    "\n",
    "x_train = tokenize.texts_to_matrix(train_posts)\n",
    "x_test = tokenize.texts_to_matrix(test_posts)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_tags)\n",
    "y_train = encoder.transform(train_tags)\n",
    "y_test = encoder.transform(test_tags)\n",
    "\n",
    "num_classes = np.max(y_train) + 1\n",
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "y_test = utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "747/747 [==============================] - ETA:  - ETA:  - 0s 83us/step\n",
      "Test accuracy: 0.3855421686746988\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## some more exploring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['cleantext'].values.astype(str), df['label'].values.astype(str), random_state = 0)\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.300796812749004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.25      0.33       118\n",
      "           1       0.42      0.21      0.28       117\n",
      "          10       0.18      0.40      0.24        25\n",
      "           2       0.26      0.50      0.34        20\n",
      "           3       0.12      0.25      0.16        12\n",
      "           4       0.20      0.62      0.30        13\n",
      "           6       0.10      0.18      0.13        22\n",
      "           7       0.57      0.41      0.48       121\n",
      "           8       0.09      0.67      0.15         6\n",
      "           9       0.18      0.19      0.18        48\n",
      "\n",
      "    accuracy                           0.30       502\n",
      "   macro avg       0.26      0.37      0.26       502\n",
      "weighted avg       0.40      0.30      0.32       502\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.27054108216432865\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.28      0.36       118\n",
      "           1       0.53      0.15      0.23       117\n",
      "          10       0.07      0.12      0.09        25\n",
      "           2       0.15      0.35      0.21        20\n",
      "           3       0.15      0.58      0.24        12\n",
      "           4       0.19      0.54      0.28        13\n",
      "           6       0.11      0.24      0.15        21\n",
      "           7       0.48      0.38      0.43       121\n",
      "           8       0.10      0.80      0.17         5\n",
      "           9       0.12      0.13      0.12        47\n",
      "\n",
      "    accuracy                           0.27       499\n",
      "   macro avg       0.24      0.36      0.23       499\n",
      "weighted avg       0.40      0.27      0.29       499\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.26961770623742454\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.28      0.35       118\n",
      "           1       0.37      0.15      0.22       117\n",
      "          10       0.00      0.00      0.00        25\n",
      "           2       0.11      0.25      0.15        20\n",
      "           3       0.12      0.36      0.18        11\n",
      "           4       0.23      0.67      0.34        12\n",
      "           6       0.17      0.29      0.21        21\n",
      "           7       0.48      0.39      0.43       121\n",
      "           8       0.07      0.60      0.12         5\n",
      "           9       0.22      0.21      0.22        47\n",
      "\n",
      "    accuracy                           0.27       497\n",
      "   macro avg       0.22      0.32      0.22       497\n",
      "weighted avg       0.36      0.27      0.29       497\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.24798387096774194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.20      0.29       118\n",
      "           1       0.43      0.17      0.25       116\n",
      "          10       0.09      0.16      0.11        25\n",
      "           2       0.14      0.30      0.19        20\n",
      "           3       0.12      0.45      0.19        11\n",
      "           4       0.19      0.58      0.29        12\n",
      "           6       0.15      0.29      0.20        21\n",
      "           7       0.43      0.32      0.37       121\n",
      "           8       0.04      0.40      0.08         5\n",
      "           9       0.17      0.21      0.19        47\n",
      "\n",
      "    accuracy                           0.25       496\n",
      "   macro avg       0.23      0.31      0.21       496\n",
      "weighted avg       0.37      0.25      0.27       496\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.2828282828282828\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.31      0.40       117\n",
      "           1       0.49      0.17      0.25       116\n",
      "          10       0.09      0.20      0.12        25\n",
      "           2       0.19      0.30      0.24        20\n",
      "           3       0.03      0.09      0.05        11\n",
      "           4       0.19      0.75      0.31        12\n",
      "           6       0.11      0.19      0.14        21\n",
      "           7       0.49      0.42      0.45       121\n",
      "           8       0.06      0.60      0.12         5\n",
      "           9       0.14      0.11      0.12        47\n",
      "\n",
      "    accuracy                           0.28       495\n",
      "   macro avg       0.24      0.31      0.22       495\n",
      "weighted avg       0.40      0.28      0.31       495\n",
      "\n",
      "--------------------------------------------------\n",
      "accuracy: 27.44% (+/- 1.73%)\n",
      "precision: 23.72% (+/- 1.28%)\n",
      "recall: 33.33% (+/- 2.35%)\n",
      "f1 score: 22.86% (+/- 1.59%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lr_cv(split, df['cleantext'].values.astype(str), df['label'].values.astype(str), NM3_pipeline, avg_method)\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "CV = split\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "for model in models:\n",
    "  model_name = model.__class__.__name__\n",
    "  accuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=CV)\n",
    "  for fold_idx, accuracy in enumerate(accuracies):\n",
    "    entries.append((model_name, fold_idx, accuracy))\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.boxplot(x='model_name', y='accuracy', data=cv_df)\n",
    "sns.stripplot(x='model_name', y='accuracy', data=cv_df, \n",
    "              size=8, jitter=True, edgecolor=\"gray\", linewidth=2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_name\n",
       "LinearSVC                 0.494638\n",
       "LogisticRegression        0.474123\n",
       "MultinomialNB             0.444368\n",
       "RandomForestClassifier    0.372468\n",
       "Name: accuracy, dtype: float64"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df.groupby('model_name').accuracy.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "model = LinearSVC()\n",
    "\n",
    "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(features, labels, df.index, test_size=0.33, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = df.label.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d',\n",
    "            xticklabels=label_list, yticklabels=label_list)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.67      0.57       173\n",
      "           6       0.44      0.48      0.46       193\n",
      "           8       0.24      0.17      0.20        40\n",
      "           4       0.53      0.21      0.30        38\n",
      "           7       0.25      0.21      0.23        14\n",
      "           1       0.75      0.50      0.60        24\n",
      "           2       0.73      0.65      0.69        37\n",
      "          10       0.61      0.64      0.63       214\n",
      "           9       1.00      0.14      0.25         7\n",
      "           3       0.43      0.27      0.33        82\n",
      "\n",
      "    accuracy                           0.51       822\n",
      "   macro avg       0.55      0.40      0.43       822\n",
      "weighted avg       0.52      0.51      0.50       822\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, y_pred, \n",
    "                                    target_names=df['label'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2489, 1235)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##failed attemp with using chi2 on imbalanced data\n",
    "\n",
    "# tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n",
    "# features = tfidf.fit_transform(df.cleantext).toarray()\n",
    "# labels = df.label\n",
    "# features.shape\n",
    "\n",
    "# label_list = df[['label']].drop_duplicates().sort_values('label')\n",
    "\n",
    "\n",
    "# from sklearn.feature_selection import chi2\n",
    "# N = 2\n",
    "# for i in sorted(label_list.values):\n",
    "#   features_chi2 = chi2(features, labels == i)\n",
    "#   indices = np.argsort(features_chi2[0])\n",
    "#   feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "#   unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "#   bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "#   print(\"  . Most correlated unigrams:\\n. {}\".format('\\n. '.join(unigrams[-N:])))\n",
    "#   print(\"  . Most correlated bigrams:\\n. {}\".format('\\n. '.join(bigrams[-N:])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
